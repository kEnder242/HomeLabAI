import os
import json
import logging
import datetime
import asyncio
from typing import List, Dict

# Paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DRAFTS_DIR = os.path.expanduser("~/AcmeLab/drafts")
CONFIG_FILE = os.path.join(BASE_DIR, "../config/recruiter_config.json")


def load_config():
    default = {
        "target_roles": ["Senior Platform Telemetry Engineer"],
        "target_companies": ["NVIDIA"],
        "keywords": ["telemetry"]
    }
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r') as f:
                return json.load(f)
        except Exception:
            pass
    return default


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [RECRUITER] %(message)s'
)
config = load_config()


class NightlyRecruiter:
    def __init__(self, archive_client=None, brain_client=None):
        self.archive = archive_client  # Injected dependency for Archive Node
        self.brain = brain_client      # Injected dependency for Brain Node
        self.config = config

    async def fetch_career_context(self):
        """Retrieves the 3x3 CVT summary from the Archive Node."""
        if not self.archive:
            return "Expert in Silicon Validation and Telemetry. 18 years experience."
        try:
            # Call the real CVT builder tool in Archive Node
            res = await self.archive.call_tool("build_cv_summary", arguments={})
            return res.content[0].text
        except Exception as e:
            logging.error(f"[RECRUITER] CVT Fetch Failed: {e}")
            return "Expert in Silicon Validation and Telemetry. 18 years experience."

    async def search_for_jobs(self, search_results: List[Dict] = None) -> List[Dict]:
        """
        Uses provided results or stubs to identify target listings.
        """
        if search_results:
            return search_results

        return [
            {
                "title": "Senior Telemetry Architect",
                "company": "NVIDIA",
                "url": "https://nvidia.wd1.myworkdayjobs.com/..."
            }
        ]

    async def generate_brief(self, jobs: List[Dict], context: str) -> str:
        """
        Synthesizes the Job Brief (The Fridge Note).
        """
        date_str = datetime.datetime.now().strftime("%Y-%m-%d")
        filename = f"job_brief_{date_str}.md"
        path = os.path.join(DRAFTS_DIR, filename)

        content = f"# üïµÔ∏è Nightly Recruiter Brief: {date_str}\n\n"
        content += f"**Context:** {context[:100]}...\n\n"
        content += "## üéØ Top Targets\n"

        for job in jobs:
            content += f"*   **{job['title']}** @ {job['company']}\n"
            content += f"    *   [Apply Here]({job['url']})\n"
            content += "    *   *Match Score:* High (Silicon + Python)\n"

        content += "\n\n---\n*Generated by HomeLabAI (The Nightly Recruiter)*"

        os.makedirs(DRAFTS_DIR, exist_ok=True)
        with open(path, "w") as f:
            f.write(content)

        return path


async def run_recruiter_task(archive_interface=None, brain_interface=None):
    """
    The entry point for the 'Alarm Clock'.
    """
    recruiter = NightlyRecruiter(archive_interface, brain_interface)
    logging.info("Waking up for Nightly Recruitment drive...")

    ctx = await recruiter.fetch_career_context()
    jobs = await recruiter.search_for_jobs()
    brief_path = await recruiter.generate_brief(jobs, ctx)

    # Notify the Pager
    try:
        rel_path = "../../Portfolio_Dev/field_notes/data/pager_activity.json"
        pager_path = os.path.join(BASE_DIR, rel_path)
        if os.path.exists(pager_path):
            with open(pager_path, "r") as f:
                pager = json.load(f)

            pager.append({
                "timestamp": datetime.datetime.now().isoformat(),
                "source": "Recruiter",
                "severity": "INFO",
                "message": f"Nightly Brief Ready: {os.path.basename(brief_path)}"
            })

            with open(pager_path, "w") as f:
                json.dump(pager[-20:], f, indent=2)
    except Exception as e:
        logging.error(f"[RECRUITER] Pager Notification Failed: {e}")

    logging.info(f"Recruitment Drive Complete. Brief saved to: {brief_path}")

    # [FEAT-088] Recruiter Dashboard Reporting
    try:
        report_path = os.path.join(BASE_DIR, "../../Portfolio_Dev/field_notes/data/recruiter_report.json")
        report = {
            "last_run": datetime.datetime.now().isoformat(),
            "brief_path": os.path.basename(brief_path),
            "jobs_found": len(jobs),
            "top_targets": [f"{j['title']} @ {j['company']}" for j in jobs[:3]]
        }
        with open(report_path, "w") as f:
            json.dump(report, f, indent=2)
    except Exception as e:
        logging.error(f"[RECRUITER] Report Generation Failed: {e}")

    return brief_path


if __name__ == "__main__":
    asyncio.run(run_recruiter_task())

from mcp.server.fastmcp import FastMCP
import logging
import sys
import os
import json
import glob
import re
import datetime

# Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [ARCHITECT] %(levelname)s - %(message)s',
    stream=sys.stderr
)

mcp = FastMCP("The Architect")

# Paths
FIELD_NOTES_DATA = os.path.expanduser("~/Dev_Lab/Portfolio_Dev/field_notes/data")
SEMANTIC_MAP_FILE = os.path.join(FIELD_NOTES_DATA, "semantic_map.json")


@mcp.tool()
async def generate_bkm(topic: str, category: str = "validation") -> str:
    """The Blueprint Generator: Creates a high-density BKM template."""
    template = f"""# BKM: {topic.upper()}
**Category:** {category.capitalize()}
**Status:** DRAFT (Architect Node)

## ðŸŽï¸ 1. Execution (One-Liner)
`[Insert critical command here]`

## ðŸ§ª 2. Validation Logic
- [ ] Step 1: Verify [X]
- [ ] Step 2: Monitor [Y]

## ðŸ¤• 3. Scars (Known Failures)
- Failure A: [Describe] -> Mitigation: [Describe]

---
*Generated by The Architect*
"""
    return template


@mcp.tool()
async def build_semantic_map() -> str:
    """Refactors artifacts into a 3-layer hierarchy: Strategic, Analytical, Tactical."""
    logging.info("Architect is deepening the semantic map...")
    artifacts = glob.glob(os.path.join(FIELD_NOTES_DATA, "20*.json"))
    
    hierarchy = {
        "strategic_layer": [], # Rank 4 (Diamond) anchors
        "analytical_layer": {}, # Theme-based insight clusters
        "tactical_layer": {
            "total_events": 0,
            "year_distribution": {}
        },
        "last_refactor": datetime.datetime.now().isoformat()
    }
    
    theme_keywords = ["telemetry", "silicon", "validation", "automation", "agentic", "architecture"]

    for art_path in artifacts:
        year = os.path.basename(art_path).replace(".json", "")
        hierarchy["tactical_layer"]["year_distribution"][year] = 0
        
        try:
            with open(art_path, 'r') as f:
                data = json.load(f)
                if not isinstance(data, list):
                    continue
                
                hierarchy["tactical_layer"]["total_events"] += len(data)
                hierarchy["tactical_layer"]["year_distribution"][year] = len(data)
                
                for item in data:
                    rank = item.get('rank', 2)
                    summary = item.get('summary', '')
                    technical_gem = item.get('technical_gem', '')
                    
                    # Layer 1: Strategic (Diamond)
                    if rank >= 4:
                        hierarchy["strategic_layer"].append({
                            "year": year, 
                            "anchor": summary[:100],
                            "gem": technical_gem
                        })
                    
                    # Layer 2: Analytical (Themes)
                    for kw in theme_keywords:
                        summary_low = str(summary).lower() if summary else ""
                        gem_low = str(technical_gem).lower() if technical_gem else ""
                        
                        if kw in summary_low or kw in gem_low:
                            if kw not in hierarchy["analytical_layer"]:
                                hierarchy["analytical_layer"][kw] = []
                            # Store unique technical gems per theme
                            if technical_gem and str(technical_gem) not in [str(g.get('gem')) for g in hierarchy["analytical_layer"][kw]]:
                                hierarchy["analytical_layer"][kw].append({
                                    "year": year, 
                                    "gem": technical_gem,
                                    "summary": summary[:150] if summary else ""
                                })
        except Exception as e:
            logging.error(f"Error processing {art_path}: {e}")

    # Prune themes to top 15 high-fidelity entries
    for kw in hierarchy["analytical_layer"]:
        hierarchy["analytical_layer"][kw] = hierarchy["analytical_layer"][kw][:15]

    with open(SEMANTIC_MAP_FILE, 'w') as f:
        json.dump(hierarchy, f, indent=2)

    return f"Map Deepened. {len(hierarchy['strategic_layer'])} strategic anchors and {len(hierarchy['analytical_layer'])} analytical themes clustered."


@mcp.tool()
async def close_lab() -> str:
    """The Master Switch: Gracefully shuts down the Mind."""
    return json.dumps({
        "status": "shutdown",
        "message": "Acme Lab is closing. Goodnight."
    })


@mcp.tool()
async def triage_response(raw_text: str) -> str:
    """
    The Cognitive Dispatcher: Aggressive Extraction Filter.
    Strips conversational prefixes and malformed tool names.
    Returns: A clean JSON Tool Call block or 'TEXT'.
    """
    valid_tools = [
        "ask_brain", "deep_think", "list_cabinet", 
        "read_document", "close_lab", "generate_bkm", 
        "access_personal_history"
    ]
    
    # 1. Strip common model prefixes
    clean_text = re.sub(
        r'^(pinky|brain|system|narf|poit|tool)[:!\s]*', 
        '', raw_text, flags=re.IGNORECASE
    ).strip()
    
    # 2. Extract all JSON-like blocks
    matches = re.findall(r'(\{.*?\})', clean_text, re.DOTALL)
    
    for m in matches:
        try:
            data = json.loads(m)
            tool = data.get("tool")
            
            # 3. Correct malformed tool names (strip parentheses)
            if tool:
                tool = tool.replace('()', '').replace('[]', '').strip()
                data["tool"] = tool
            else:
                # 4. Deep Search: Check values for tool names
                for val in data.values():
                    if isinstance(val, str):
                        for vt in valid_tools:
                            if vt in val.lower():
                                return json.dumps({"tool": vt, "parameters": {}})
            
            # If it's a known tool, return ONLY the clean JSON
            if tool in valid_tools:
                return json.dumps(data)
            
            # Handle reply_to_user special case
            if not tool and "reply_to_user" in data:
                return json.dumps(data)
                
        except json.JSONDecodeError:
            continue
            
    return "TEXT"


if __name__ == "__main__":
    mcp.run()
